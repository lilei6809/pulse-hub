# PulseHub v0.2: 愿景、目标与技术规划

## 1. 简介

PulseHub v0.1 成功地验证了我们核心的数据采集和存储能力。v0.2 的核心使命是将平台从一个基础的数据采集系统，演进为一个具备强大实时处理能力的 **"CRM 中间件"** 平台。

我们的目标是构建一个能够实时响应用户行为、动态生成用户画像、并为上层应用（如营销自动化、个性化推荐）提供实时数据支持的高性能、高可扩展性的数据中枢。

## 2. v0.2 核心目标与愿景

- **实时用户画像 (Real-time User Profiles)**: 打破数据延迟，实现用户画像的毫秒级更新与查询。当用户在前端产生行为时，其画像数据应能立刻得到丰富和更新。
- **可扩展与可维护的架构 (Scalable & Maintainable Architecture)**: 引入先进的架构模式，如 "冷热路径分离" 和 "中央化配置管理"，以支持未来业务的快速增长和技术迭代。
- **未来增长的基石 (Foundation for Future Growth)**: v0.2 的架构将为未来更高级的功能（如实时客群细分、用户旅程分析、个性化营销触发等）打下坚实的基础。

## 3. 关键架构变革：冷热路径分离

为了同时满足实时性与数据完整性的要求，v0.2 将引入 **"冷热路径" (Hot/Cold Path)** 分离的架构。

```mermaid
graph TD
    subgraph "数据源 (Data Sources)"
        A[Web/App Clients]
    end

    subgraph "数据采集 (Ingestion)"
        B(Event Producer)
    end

    subgraph "消息队列 (Message Queue)"
        C{Kafka: user-activity-events}
    end

    subgraph "热路径 (Hot Path - Real-time Processing)"
        direction LR
        D[Stream Processor <br/>(Kafka Streams)]
        E((Redis <br/>/Cache/))
        F[Profile Service API]
    end

    subgraph "冷路径 (Cold Path - Archival & Batch)"
        direction LR
        G[Ingestion Service <br/>(Archiver)]
        H[(PostgreSQL <br/>/Data Warehouse/)]
    end
    
    subgraph "配置中心 (Configuration)"
        I[Config Server <br/>(Spring Cloud Config)]
    end

    A --> B
    B --> C

    C --> D
    D --> E
    E <--> F

    C --> G
    G --> H

    I -.-> D
    I -.-> F
    I -.-> G

    classDef default fill:#f9f9f9,stroke:#333,stroke-width:2px;
    classDef important fill:#ffc,stroke:#f00,stroke-width:2px;
    class A,B,C,D,E,F,G,H,I default;
```

- **热路径 (Hot Path)**:
  - **目标**: 追求极致的低延迟。
  - **流程**: 事件进入 Kafka后，由新的 `stream-processor` 服务（基于 Kafka Streams）进行实时消费、处理和丰富。处理结果（如更新后的用户画像）被写入 Redis 缓存。`profile-service` 将主要从 Redis 读取数据，对外提供低延迟的画像查询 API。
- **冷路径 (Cold Path)**:
  - **目标**: 保证数据的完整性和持久性，用于离线分析和数据归档。
  - **流程**: `ingestion-service` 的角色将转变为一个归档服务。它会订阅 Kafka 的原始事件，并将其持久化到 PostgreSQL 数据库中。

## 4. 新增与改造的组件

- **新增 `config-server`**:
  - **技术**: Spring Cloud Config，后端使用 Git 仓库。
  - **目的**: 实现所有微服务的配置统一管理、版本化控制和动态刷新，是系统走向规范化的关键一步。
- **新增 `stream-processor`**:
  - **技术**: Kafka Streams。
  - **目的**: 这是 v0.2 的实时处理核心。它负责消费原始事件，进行状态计算（如页面浏览次数）、数据丰富（如设备类型判断），并将结果更新到 Redis。
- **新增 `Redis`**:
  - **技术**: Redis。
  - **目的**: 作为高性能的内存数据库，用于缓存用户画像，支撑热路径的实时读写需求。
- **改造 `ingestion-service`**:
  - **新定位**: 从 v0.1 的主要数据处理者，转变为 v0.2 的**数据归档服务**，成为冷路径的关键部分。
- **改造 `profile-service`**:
  - **新定位**: 将主要数据源从直接访问数据库，切换为访问 Redis 缓存，以实现 API 的低延迟响应。数据库将作为其备用数据源或用于写入最终一致的数据。

## 5. v0.2 实施路线图 (源自 Task-master)

本实施计划直接源自我们的 `task-master` 项目管理工具，代表了此阶段开发工作的唯一事实来源。

- [x] **Task 7: Set up Redis Caching Layer**
  - **Description**: Integrate Redis as a high-performance, in-memory data store for caching user profiles and supporting real-time operations.
  - **Dependencies**: None
  - **Subtasks**:
    - [x] **7.1**: Configure Redis connection properties
    - [x] **7.2**: Implement Redis connection factory and template
    - [x] **7.3**: Develop cache service abstraction layer
    - [x] **7.4**: Implement TTL policies and eviction strategies
    - [x] **7.5**: Implement Redis health checks and monitoring

- [ ] **Task 9: Configure Multi-Topic Kafka Environment**
  - **Description**: Restructure the Kafka environment to handle multiple topics, separating raw events (user-activity-events) from processed results (profile-updates).
  - **Dependencies**: None
  - **Subtasks**:
    - [ ] **9.1**: Define and create Kafka topics
    - [ ] **9.2**: Design partitioning strategy
    - [ ] **9.3**: Configure replication and durability settings
    - [ ] **9.4**: Implement error handling and retry mechanisms
    - [ ] **9.5**: Set up monitoring and alerting
    - [ ] **9.6**: Integrate Kafka with Spring Boot application

- [ ] **Task 10: Create User Profile Model**
  - **Description**: Design and implement the User Profile data model to store enriched user attributes including lastActiveAt timestamp, page view counter, and device classification.
  - **Dependencies**: None
  - **Subtasks**:
    - [ ] **10.1**: Define User Profile Core Attributes
    - [ ] **10.2**: Implement Serialization/Deserialization Methods
    - [ ] **10.3**: Develop Helper Methods and Utility Functions

- [ ] **Task 11: Implement User Profile Service**
  - **Description**: Create a service to manage user profiles, including methods to retrieve, update, and cache user profile data.
  - **Dependencies**: Task 7, Task 10
  - **Subtasks**:
    - [ ] **11.1**: Define User Profile Service Interface
    - [ ] **11.2**: Implement Redis Integration for Profile Caching
    - [ ] **11.3**: Implement Database Fallback Mechanism
    - [ ] **11.4**: Develop Exception Handling Framework
    - [ ] **11.5**: Implement Cache Update Strategies

- [ ] **Task 12: Develop Real-time Event Processor**
  - **Description**: Implement a Kafka consumer service that processes incoming UserActivityEvents in real-time to update user profiles with enriched data.
  - **Dependencies**: Task 9, Task 11
  - **Subtasks**:
    - [ ] **12.1**: Configure Kafka Consumer
    - [ ] **12.2**: Implement Core Event Processing Logic
    - [ ] **12.3**: Develop User Profile Update Mechanism
    - [ ] **12.4**: Implement Comprehensive Error Handling
    - [ ] **12.5**: Set Up Monitoring and Alerting
    - [ ] **12.6**: Optimize Performance and Scalability

- [ ] **Task 13: Implement Profile REST API**
  - **Description**: Create a REST API to expose user profile data with low latency, leveraging the Redis cache for performance.
  - **Dependencies**: Task 11
  - **Subtasks**:
    - [ ] **13.1**: Implement Profile Controller
    - [ ] **13.2**: Implement Input Validation
    - [ ] **13.3**: Implement Error Handling
    - [ ] **13.4**: Create API Documentation

- [ ] **Task 14: Implement Profile Database Repository**
  - **Description**: Create a repository layer to persist user profiles in PostgreSQL as part of the cold path for long-term storage and analytics.
  - **Dependencies**: Task 10
  - **Subtasks**:
    - [ ] **14.1**: Define Profile Repository Interface
    - [ ] **14.2**: Implement Database Operations (CRUD)
    - [ ] **14.3**: Configure Transaction Management
    - [ ] **14.4**: Optimize Database Queries
    - [ ] **14.5**: Implement Error Handling 