# Data Sync Service 应用配置
server:
  port: "${Data_Sync_Service_PORT:8087}"

# 事件路由
event-routing:
  default-strategy: BATCH_SYNC
  immediate-sync-exceptions:
    - ACCOUNT_STATUS_CHANGE
    - PERMISSION_UPDATE
    - VIP_LEVEL_CHANGE
    - ORDER_CREATED
    - ORDER_PAYED
    - ORDER_CANCELLED

  
spring:
  application:
    name: data-sync-service
    
  # 使用local profile作为默认配置
  profiles:
    active: "${SPRING_PROFILES_ACTIVE:local}"  # 默认本地
    
  # Redis配置 - 用于分布式锁和版本控制
  data:
    redis:
      host: "${REDIS_HOST:localhost}"
      port: "${REDIS_PORT:6379}"
      timeout: 3000
      connect-timeout: 3000
      jedis:
        pool:
          max-active: 8
          max-wait: -1
          max-idle: 8
          min-idle: 0
    
    mongodb:
      uri: "${SPRING_DATA_MONGODB_URI:mongodb://${MONGODB_HOST:localhost}:${MONGODB_PORT:27017}/${MONGODB_DATABASE:pulsehub_profiles}}"
      database: "${MONGODB_DATABASE:pulsehub_profiles}"
        
  # MongoDB配置 - 目标数据存储
  
  # Kafka配置 - 消息队列
  kafka:
    bootstrap-servers: "${KAFKA_BOOTSTRAP_SERVERS:kafka:29092}"
    producer:
      retries: 0  # 禁用Kafka自带重试，使用@Retryable
      acks: 1
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: io.confluent.kafka.serializers.protobuf.KafkaProtobufDeserializer
    consumer:
      immediate-sync-group:
        group-id: immediate-sync-group
        auto-offset-reset: earliest
        max-poll-records: 1        # 立即同步单条处理
        fetch-min-size: 1
        concurrency: 2             # 2个并发消费者
        key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
        value-deserializer: io.confluent.kafka.serializers.protobuf.KafkaProtobufDeserializer
        properties:
          schema.registry.url: http://schema-registry:8081
          specific.protobuf.value.type: com.pulsehub.common.proto.UserProfileSyncEvent
      batch-sync-group:
        group-id: batch-sync-group
        auto-offset-reset: earliest
        max-poll-records: 10       # 批量同步10条处理
        fetch-min-size: 1024
        concurrency: 5             # 5个并发消费者
        key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
        value-deserializer: io.confluent.kafka.serializers.protobuf.KafkaProtobufDeserializer
        properties:
          schema.registry.url: http://schema-registry:8081
          specific.protobuf.value.type: com.pulsehub.common.proto.UserProfileSyncEvent
      properties:
        spring.json.trusted.packages: "com.pulsehub.*"
    # Kafka Streams 事件路由器配置
    streams:
      application-id: data-sync-router
      bootstrap-servers: "${KAFKA_BOOTSTRAP_SERVERS:kafka:29092}"
      properties:
        processing.guarantee: exactly_once_v2  # 确保不重复路由
        num.stream.threads: 1                  # 单线程处理路由逻辑
        cache.max.bytes.buffering: 0           # 禁用缓存，保证实时路由
        commit.interval.ms: 1000               # 1秒提交一次offset
        default.key.serde: org.apache.kafka.common.serialization.Serdes$StringSerde
        default.value.serde: org.springframework.kafka.support.serializer.JsonSerde
        
  # 异步任务配置, 线程池配置
  task:
    execution:
      pool:
        core-size: 5
        max-size: 20
        queue-capacity: 100
# 数据同步服务专用配置
sync:
  # 批量同步配置
  batch:
    interval: 60000        # 批量同步间隔(毫秒) - 1分钟
    batch-size: 100        # 每批处理的用户数量
    max-users: 2000        # 最大预处理用户数量
    timeout: 30000         # 批量处理超时时间(毫秒)

  # 立即同步配置
  immediate:
    timeout: 5000          # 立即同步超时时间(毫秒)
    retry-count: 3         # 重试次数
    retry-delay: 1000      # 重试间隔(毫秒)

  # 分布式锁配置
  lock:
    default-timeout: 5000      # 默认锁超时时间(毫秒)
    immediate-timeout: 10000   # 立即同步锁超时时间(毫秒)
    batch-timeout: 30000       # 批量同步锁超时时间(毫秒)

  # Kafka Topic配置
  topics:
    profile-sync: "user_profile_sync_event"
    immediate-sync: "profile_immediate_sync_event"
    batch-sync: "profile_batch_sync_event"

  # 清理配置
  cleanup:
    dirty-flags-ttl: 86400000  # dirty flags TTL(毫秒) - 24小时
    failed-records-ttl: 604800000  # 失败记录TTL(毫秒) - 7天

# 监控和管理配置
management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus
  endpoint:
    health:
      show-details: when_authorized
  metrics:
    tags:
      service: data-sync-service
  prometheus:
    metrics:
      export:
        enabled: true
# 日志配置
logging:
  level:
    com.pulsehub.datasync: DEBUG
    com.pulsehub.common.redis: DEBUG
    org.springframework.kafka: INFO
    org.springframework.data.mongodb: INFO
    org.springframework.retry: DEBUG
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level [%logger{36}] - %msg%n"